{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00000-e91b1ad7-05a5-48c2-8c81-523c66e9b15f",
        "deepnote_cell_type": "markdown",
        "id": "rGrruB7MJgxf"
      },
      "source": [
        "# ***Introduction***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this report, I will be looking at Covid-19 data for the United States. The data is purposfully cut down from all 50 states for the sake of saving space, but the actions I perfrom on it will hold up if applied in a distributed computing setting where I can use the resources of mulitple nodes. I will narrow my original dataset down to the three [most republican states](https://worldpopulationreview.com/state-rankings/most-republican-states) which are Wyoming, Utah, and Oklahoma. Then I will take the corespoinding [most democratic states](https://worldpopulationreview.com/state-rankings/most-democratic-statesps://) which are Hawaii, Vermont, and California. \n",
        "\n",
        "\n",
        "I chose this project because during the Covid-19 pandemic, there was a lot of debate between political parties regarding what policies (if any) we should put in place to fight the virus. By looking at the most extreme ends of the political spectrum, hopfully we can uncover details about what policies worked best to fight the virus, in hopes of being more prepaired for the next global pandemic."
      ],
      "metadata": {
        "id": "9qQaFpDKfDrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup / Imports / SparkContext"
      ],
      "metadata": {
        "id": "vqTioswuKdRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "from time import sleep\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "from pyspark.sql import types as sparktypes\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "sc = SparkContext() \n",
        "spark = SparkSession(sc)\n",
        "\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "id": "1ZBRjZrAKfh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe16087d-bf37-4eec-b9fd-78c24c6efd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 52 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 92.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=b8f12e7ab628be47f2a10c8fe144af1f9d53779633d2dbaa4b09624e1a861a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 36.6 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-66b4726d-c84b-4710-baab-d780d1bf8f03",
        "deepnote_cell_type": "markdown",
        "id": "mi_L6F4pJgxl"
      },
      "source": [
        "# ***Datasets***\n",
        "\n",
        "\n",
        "For this final project, I obtained United States Covid-19 data from datahub.io. I used the [us_simplified.csv](https://datahub.io/core/covid-19#resource-us_simplified) dataset because of its straightforward nature and clean headings. \n",
        "\n",
        "Structure:\n",
        "The us_simplified.csv file has 6 columns: \n",
        "\n",
        "\n",
        "*   Date\n",
        "*   Admin2 - The county of the given state.\n",
        "\n",
        "*   Province/State\n",
        "*   Confimed - The number of confimed cases for a given date.\n",
        "\n",
        "\n",
        "*   Deaths - The number of deaths for a given date.\n",
        "\n",
        "*   Country/Region\n",
        "\n",
        "\n",
        "The time period of when this data is collected is 2020-01-22 to 2022-01-23. As alluded to in the introduction, I will be focusing on data for Wyoming, Utah, Oklahoma, Hawaii, Vermont, and California."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "H-GcN4ucCScs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # this is how I access my data from the drive.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG_57GlUL5oE",
        "outputId": "f2db9ffa-8f8c-4448-978b-88c1f9ab4509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn the csv file into a dataframe:"
      ],
      "metadata": {
        "id": "qvCijIPULI0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00012-8cfe56f0-c5e8-4d83-a2fa-3e85108f624a",
        "deepnote_cell_type": "code",
        "id": "ImXJyyXMJgxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b39e58-9955-488b-acb1-2167864c9360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------+---------+------+--------------+\n",
            "|      Date| Admin2|Province/State|Confirmed|Deaths|Country/Region|\n",
            "+----------+-------+--------------+---------+------+--------------+\n",
            "|2020-01-22|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-23|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-24|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-25|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-26|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-27|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-28|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-29|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-30|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-01-31|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-01|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-02|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-03|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-04|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-05|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-06|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-07|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-08|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-09|Autauga|       Alabama|        0|     0|            US|\n",
            "|2020-02-10|Autauga|       Alabama|        0|     0|            US|\n",
            "+----------+-------+--------------+---------+------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "original_df = spark.read.option(\"header\",True).csv(\"/content/drive/MyDrive/CSC 369/us_simplified.csv\")\n",
        "original_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00002-6f9f0611-f0ae-4617-b092-fd5be36cd0d5",
        "deepnote_cell_type": "markdown",
        "id": "veryHr5vJgxm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-3f3366d4-f0f6-4aee-b495-0499a2d9058b",
        "deepnote_cell_type": "markdown",
        "id": "k6woQFDaJgxq"
      },
      "source": [
        "## ***Question***\n",
        "When deciding on what question to ask, I focused on one that would lead us to discover common factors that minimized the impact of Covid-19 most effictivly, while transforming the data in meaningful ways.\n",
        "\n",
        "\n",
        "*   Does political party of a given state have an association with the ratio of confirmed cases to deaths?\n",
        "\n",
        "  *   What other factors might be influencing this ratio?\n",
        "  *   How can we use the results of this analysis to make better decisions during the next pandmeic?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Problem Decompostition***\n",
        "\n",
        "\n",
        " In the following section you will see me manipulate the data in many ways en route to our final result. Here is a breif overview of these steps:\n",
        "\n",
        "\n",
        "*   Take the full dataset of 50 states and narrow it down to the six I want.\n",
        "*   Make sure that each column in my dataframe is the correct data type for easier manipulation down the road.\n",
        "\n",
        "*   Find the sum of all confimed cases and deaths for each state over our time period.\n",
        "*   Use the sums found in the previous step to compute the ratio of confimed cases to deaths.\n",
        "\n",
        "*   Find the average ratio for each political party.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bOvqeLnoftGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Narrow down the data to my desired 6 states "
      ],
      "metadata": {
        "id": "RfTCO5UVIUqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = original_df.withColumnRenamed(\"Province/State\", \"State\").withColumnRenamed(\"Country/Region\", \"Country\") #rename for clarity\n",
        "df = df.select(\"Date\", \"State\", \"Confirmed\", \"Deaths\", \"Country\") # select only the columns we need.\n",
        "df = df.filter((df[\"State\"] == \"Wyoming\") | \n",
        "               (df[\"State\"] == \"Utah\") |\n",
        "               (df[\"State\"] == \"Oklahoma\") |\n",
        "               (df[\"State\"] == \"Hawaii\") |\n",
        "               (df[\"State\"] == \"Vermont\") |\n",
        "               (df[\"State\"] == \"California\")) # now we have only the 6 states that we need.\n",
        "#cast so that we can do math later on\n",
        "df = df.withColumn(\"Confirmed\", col(\"Confirmed\").cast(\"int\")).withColumn(\"Deaths\", col(\"Deaths\").cast(\"int\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpqWewpKIgaQ",
        "outputId": "be70337c-16f8-4895-c234-13646ee2893b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+---------+------+-------+\n",
            "|      Date|     State|Confirmed|Deaths|Country|\n",
            "+----------+----------+---------+------+-------+\n",
            "|2020-01-22|California|        0|     0|     US|\n",
            "|2020-01-23|California|        0|     0|     US|\n",
            "|2020-01-24|California|        0|     0|     US|\n",
            "|2020-01-25|California|        0|     0|     US|\n",
            "|2020-01-26|California|        0|     0|     US|\n",
            "|2020-01-27|California|        0|     0|     US|\n",
            "|2020-01-28|California|        0|     0|     US|\n",
            "|2020-01-29|California|        0|     0|     US|\n",
            "|2020-01-30|California|        0|     0|     US|\n",
            "|2020-01-31|California|        0|     0|     US|\n",
            "|2020-02-01|California|        0|     0|     US|\n",
            "|2020-02-02|California|        0|     0|     US|\n",
            "|2020-02-03|California|        0|     0|     US|\n",
            "|2020-02-04|California|        0|     0|     US|\n",
            "|2020-02-05|California|        0|     0|     US|\n",
            "|2020-02-06|California|        0|     0|     US|\n",
            "|2020-02-07|California|        0|     0|     US|\n",
            "|2020-02-08|California|        0|     0|     US|\n",
            "|2020-02-09|California|        0|     0|     US|\n",
            "|2020-02-10|California|        0|     0|     US|\n",
            "+----------+----------+---------+------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we find the total deaths and total confirmed cases for each state."
      ],
      "metadata": {
        "id": "q9giQpSYR-kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.groupBy(\"State\").sum(\"Confirmed\")\n",
        "df2 = df.groupBy(\"State\").sum(\"Deaths\")\n",
        "df3 = df1.join(df2, \"State\")\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tAlZXgNUtMh",
        "outputId": "3b1049b6-10bf-4928-9f22-5c8fcfcf15b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+-----------+\n",
            "|     State|sum(Confirmed)|sum(Deaths)|\n",
            "+----------+--------------+-----------+\n",
            "|    Hawaii|      24421302|     276712|\n",
            "|California|    1839595402|   27149306|\n",
            "|      Utah|     199344756|    1112698|\n",
            "|   Vermont|      12554607|     128605|\n",
            "|  Oklahoma|     223813728|    3244662|\n",
            "|   Wyoming|      31941561|     373257|\n",
            "+----------+--------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that we have left now is to find the ratio of confirmed cases to deaths for each state.\n"
      ],
      "metadata": {
        "id": "Bj_ZL8pLXfJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratio = df3.withColumn(\"Ratio\", df3[\"sum(Confirmed)\"]/df3[\"sum(Deaths)\"])"
      ],
      "metadata": {
        "id": "KIWEk_OTXnDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add an additional column so that we can clearly see the political party of the given state.\n",
        "R = Republican \n",
        "D = Democrat"
      ],
      "metadata": {
        "id": "1fLSdQfyOvxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df_ratio = df_ratio.withColumn(\"Party\", \\\n",
        "                   when((df[\"State\"] == \"Wyoming\"), \"R\") \\\n",
        "                   .when((df[\"State\"] == \"Utah\"), \"R\") \\\n",
        "                   .when((df[\"State\"] == \"Oklahoma\"), \"R\") \\\n",
        "                   .when((df[\"State\"] == \"Hawaii\"), \"D\") \\\n",
        "                   .when((df[\"State\"] == \"Vermont\"), \"D\") \\\n",
        "                   .when((df[\"State\"] == \"California\"), \"D\"))"
      ],
      "metadata": {
        "id": "Arcr-dqMOukp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Results***\n",
        "The chart below shows the ratio for each of our six states."
      ],
      "metadata": {
        "id": "BvqjvEVufyqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratio.orderBy(\"Ratio\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO9p7iUOaGwV",
        "outputId": "9820c663-093b-4f51-d7a1-ee871083f9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+-----------+-----------------+-----+\n",
            "|     State|sum(Confirmed)|sum(Deaths)|            Ratio|Party|\n",
            "+----------+--------------+-----------+-----------------+-----+\n",
            "|      Utah|     199344756|    1112698|179.1544120686835|    R|\n",
            "|   Vermont|      12554607|     128605|97.62145328719723|    D|\n",
            "|    Hawaii|      24421302|     276712|  88.255305154818|    D|\n",
            "|   Wyoming|      31941561|     373257|85.57524976088861|    R|\n",
            "|  Oklahoma|     223813728|    3244662|68.97905791111678|    R|\n",
            "|California|    1839595402|   27149306|67.75846874317892|    D|\n",
            "+----------+--------------+-----------+-----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "It is important to understand what our data means before we extrapolate from it. In this context, the larger the ratio of confirmed cases to deaths, the better. In other words, you could say that for every 179 people who got Covid-19 in Utah from 2020-01-22 to 2022-01-23, one person died. "
      ],
      "metadata": {
        "id": "6dBeSIfQaRQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the state with the worst ratio is California, and the one with the best is Utah. Right off the bat, this points to a stark difference between Republican and Democratic states and their coresponding ratios. With that being said, we must be careful in only looking at the minimum and maximum ratio, as we don't want outliers to skew our view of what is actually happening.\n",
        "\n",
        "To solve this problem, we sould look at the average ratio for each political party:"
      ],
      "metadata": {
        "id": "k9bBt8jVKhTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratio.groupBy(\"Party\").avg(\"Ratio\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMepi--HgX1r",
        "outputId": "f97d8651-6ba2-4cc6-a8f1-0e3520e3b128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+\n",
            "|Party|        avg(Ratio)|\n",
            "+-----+------------------+\n",
            "|    D| 84.54507572839806|\n",
            "|    R|111.23623991356295|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we see a different perspective as the average ratio for the dems is significantly smaller than that of the conservative states. "
      ],
      "metadata": {
        "id": "tW5Rmx9lL4NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# So what is this data telling us?\n",
        "In short, not very much. There are so many factors that could contribute to the difference in the ratio between states. Below I will list a few that came to mind.\n",
        "\n",
        "\n",
        "*   Quality of health care within the state.\n",
        "*   Percentage of the population that is elderly.\n",
        "\n",
        "*   Availablilty of the vaccine.\n",
        "*   Percentage of individuals that took the vaccine.\n",
        "\n",
        "*   Amount of people in close-quarters living situations\n",
        "*   Overall wealth of the individuals within the population of the state.\n",
        "\n",
        "Although it is very convienient to try to say one political party handled the pandemic better than the other, there are so many factors that could have influenced the ratio of cases to deaths that it would be irresponsible to comment on policy recommendations. \n",
        "\n",
        "One concrete thing that we can do with these results would be to look at the way California handled the pandemic verses Utah and see if we can learn any lessons for next time. Unfortuantly that research is beyond the scope of this project, so I will save that for another time.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0sIkm9J7MI90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusion***\n",
        "It was very exciting processing this data and telling a story using these distributed computing tools. Knowing how important data is in our modern world makes me even more motivated to explore this topic in greater detail. The most important thing I learned is that we must be careful drawing conclusions from a data analysis because we often fail to consider all factors at play. "
      ],
      "metadata": {
        "id": "S2aG3yCnf44d"
      }
    }
  ],
  "metadata": {
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "34558ca3-99ac-48c4-8d6f-270fc26fe9dc",
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}